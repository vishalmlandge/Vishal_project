{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e143e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Running on CPU.\n",
      "Cell 1 time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "global_start_time = time.time()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('Running on CPU.')\n",
    "\n",
    "cell_start = time.time()\n",
    "print(f'Cell 1 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329b6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 10000\n",
      "Label distribution:\n",
      "toxic            904\n",
      "severe_toxic      91\n",
      "obscene          498\n",
      "threat            17\n",
      "insult           475\n",
      "identity_hate     87\n",
      "dtype: int64\n",
      "Cell 2 time: 23.18 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Load dataset\n",
    "english_data_path = 'train.csv'\n",
    "\n",
    "if not os.path.exists(english_data_path):\n",
    "    raise FileNotFoundError(f'Dataset not found at {os.path.abspath(english_data_path)}')\n",
    "\n",
    "# Load train.csv dataset (sample 10,000 rows)\n",
    "df = pd.read_csv(english_data_path).sample(10000, random_state=42)\n",
    "df['language'] = df['comment_text'].apply(lambda x: 'marathi_hindi' if bool(re.search(r'[\\u0900-\\u097F]', str(x))) else 'english')\n",
    "\n",
    "texts = df['comment_text'].tolist()\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "print(f'Total dataset size: {len(df)}')\n",
    "print(f'Label distribution:\\n{df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].sum()}')\n",
    "print(f'Cell 2 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d70848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved model to ./multilingual_toxic_detector_model\n",
      "Cell 3 time: 20.48 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Load tokenizer and model\n",
    "local_path = './multilingual_toxic_detector_model'\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-multilingual-cased',\n",
    "        num_labels=6,\n",
    "        problem_type='multi_label_classification'\n",
    "    )\n",
    "    tokenizer.save_pretrained(local_path)\n",
    "    model.save_pretrained(local_path)\n",
    "    print(f'Downloaded and saved model to {local_path}')\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(local_path)\n",
    "config = DistilBertConfig.from_pretrained(\n",
    "    local_path,\n",
    "    num_labels=6,\n",
    "    problem_type='multi_label_classification',\n",
    "    hidden_dropout_prob=0.3,\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(local_path, config=config, ignore_mismatched_sizes=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Cell 3 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72174905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8000, Validation size: 1000, Test size: 1000\n",
      "Cell 4 time: 12.47 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Split data: 80% train, 10% validation, 10% test\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Encode texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "print(f'Train size: {len(train_texts)}, Validation size: {len(val_texts)}, Test size: {len(test_texts)}')\n",
    "print(f'Cell 4 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f0d9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 5 time: 1.10 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].to(device) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].to(device)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
    "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
    "test_dataset = ToxicDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "print(f'Cell 5 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420ae734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 6 time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "print(f'Cell 6 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dce5ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: Train Loss: 0.1024, Val Loss: 0.0605, Val Accuracy: 0.9110\n",
      "Epoch 2/3: Train Loss: 0.0543, Val Loss: 0.0663, Val Accuracy: 0.9110\n",
      "Epoch 3/3: Train Loss: 0.0424, Val Loss: 0.0550, Val Accuracy: 0.8990\n",
      "Training completed.\n",
      "Cell 7 time: 8769.68 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "def train_model(epochs=3, patience=2):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "            outputs = model(**inputs).logits\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                outputs = model(**inputs).logits\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping triggered.')\n",
    "                break\n",
    "\n",
    "train_model(epochs=3, patience=2)\n",
    "print('Training completed.')\n",
    "print(f'Cell 7 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16734bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.7418, Recall: 0.6109, Accuracy: 0.9040\n",
      "Cell 8 time: 103.02 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels']\n",
    "        outputs = model(**inputs).logits\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "precision = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Test Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(f'Cell 8 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d305c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring example comment: Nature is beautiful but some people are just awful\n",
      "Processing comment: 'Nature is beautiful but some people are just awful'\n",
      "Result: {'is_toxic': False, 'toxic_words': [], 'scores': {'toxic': 0.021533053368330002, 'severe_toxic': 8.854931365931407e-05, 'obscene': 0.0016309237107634544, 'threat': 0.0001629415201023221, 'insult': 0.0014743577921763062, 'identity_hate': 0.00025027836090885103}}\n",
      "\n",
      "Scoring example comment: are murkha\n",
      "Processing comment: 'are murkha'\n",
      "Result: {'is_toxic': True, 'toxic_words': ['murkha'], 'scores': {'toxic': 0.9014849662780762, 'severe_toxic': 0.08181779831647873, 'obscene': 0.44995173811912537, 'threat': 0.05206559970974922, 'insult': 0.5787873268127441, 'identity_hate': 0.14748023450374603}}\n",
      "\n",
      "Scoring example comment: a/s/h/h/o/l\n",
      "Processing comment: 'a/s/h/h/o/l'\n",
      "Result: {'is_toxic': True, 'toxic_words': ['a/s/h/h/o/l'], 'scores': {'toxic': 0.14381268620491028, 'severe_toxic': 0.010317770764231682, 'obscene': 0.044958434998989105, 'threat': 0.014101111330091953, 'insult': 0.05535968020558357, 'identity_hate': 0.01594006083905697}}\n",
      "\n",
      "Scoring example comment: f..ck\n",
      "Processing comment: 'f..ck'\n",
      "Result: {'is_toxic': True, 'toxic_words': ['f', 'ck'], 'scores': {'toxic': 0.7665501236915588, 'severe_toxic': 0.23103532195091248, 'obscene': 0.5810731649398804, 'threat': 0.12753871083259583, 'insult': 0.5222229957580566, 'identity_hate': 0.1676531732082367}}\n",
      "\n",
      "Scoring example comment: WTH\n",
      "Processing comment: 'WTH'\n",
      "Result: {'is_toxic': True, 'toxic_words': ['wth'], 'scores': {'toxic': 0.5604020357131958, 'severe_toxic': 0.1979958713054657, 'obscene': 0.3205161392688751, 'threat': 0.18939658999443054, 'insult': 0.4024830460548401, 'identity_hate': 0.2196529060602188}}\n",
      "Cell 9 time: 1.75 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "def is_marathi_hindi(text):\n",
    "    devanagari_regex = r'[\\u0900-\\u097F]'\n",
    "    return bool(re.search(devanagari_regex, text))\n",
    "\n",
    "def score_comment(text):\n",
    "    print(f'Processing comment: {text!r}')\n",
    "    text = ' '.join(text.strip().split())\n",
    "    \n",
    "    # Check for toxic patterns: asterisk, backslash, forward slash, or ellipsis\n",
    "    has_toxic_pattern = bool(re.search(r'\\b[\\w*\\\\\\/]*[\\*\\\\\\/\\.]{1,}[\\w*\\\\\\/]*\\b', text))\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "    \n",
    "    # Define categories (aligned with model training)\n",
    "    categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    scores = {cat: float(prob) for cat, prob in zip(categories, probs)}\n",
    "    \n",
    "    # Extract words\n",
    "    words = re.findall(r'\\b[\\w\\'*\\\\\\/-]+\\b', text.lower())\n",
    "    \n",
    "    # Determine if text is toxic (model threshold 0.3 or toxic pattern)\n",
    "    is_toxic = has_toxic_pattern or any(prob > 0.3 for prob in probs)\n",
    "    \n",
    "    # Extract toxic words\n",
    "    toxic_words = []\n",
    "    if is_toxic:\n",
    "        for word in words:\n",
    "            if word in ['tu', 'ahe', 'kya', 'kar', 'raha', 'hai', 'ka', 'se']:\n",
    "                continue\n",
    "            if any(p in word for p in ['*', '\\\\', '/', '...']):\n",
    "                toxic_words.append(word)\n",
    "                continue\n",
    "            word_inputs = tokenizer(word, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "            with torch.no_grad():\n",
    "                word_outputs = model(**word_inputs).logits\n",
    "            word_probs = torch.sigmoid(word_outputs).cpu().numpy()[0]\n",
    "            if any(word_prob > 0.3 for word_prob in word_probs):\n",
    "                toxic_words.append(word)\n",
    "    \n",
    "    toxic_words = list(dict.fromkeys(toxic_words))\n",
    "    \n",
    "    return {\n",
    "        'is_toxic': is_toxic,\n",
    "        'toxic_words': toxic_words,\n",
    "        'scores': scores\n",
    "    }\n",
    "\n",
    "# Test example comments\n",
    "example_comments = [\n",
    "    'Nature is beautiful but some people are just awful',\n",
    "    'are murkha',\n",
    "    'a/s/h/h/o/l',\n",
    "    'f..ck',\n",
    "    'WTH'\n",
    "]\n",
    "for comment in example_comments:\n",
    "    print(f'\\nScoring example comment: {comment}')\n",
    "    result = score_comment(comment)\n",
    "    print('Result:', result)\n",
    "\n",
    "print(f'Cell 9 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d84b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total execution time: 362.07 minutes\n",
      "Cell 10 time: 13.84 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "model.save_pretrained('./multilingual_toxic_detector_model')\n",
    "tokenizer.save_pretrained('./multilingual_toxic_detector_model')\n",
    "print(f'\\nTotal execution time: {(time.time() - global_start_time) / 60:.2f} minutes')\n",
    "\n",
    "print(f'Cell 10 time: {time.time() - cell_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8284679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
